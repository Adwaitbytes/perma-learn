{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.arrayCompare = exports.MIN_CHUNK_SIZE = exports.MAX_CHUNK_SIZE = void 0;\nexports.chunkData = chunkData;\nexports.generateLeaves = generateLeaves;\nexports.computeRootHash = computeRootHash;\nexports.generateTree = generateTree;\nexports.generateTransactionChunks = generateTransactionChunks;\nexports.buildLayers = buildLayers;\nexports.generateProofs = generateProofs;\nexports.arrayFlatten = arrayFlatten;\nexports.intToBuffer = intToBuffer;\nexports.bufferToInt = bufferToInt;\nexports.validatePath = validatePath;\nexports.debug = debug;\n/**\n * @see {@link https://github.com/ArweaveTeam/arweave/blob/fbc381e0e36efffa45d13f2faa6199d3766edaa2/apps/arweave/src/ar_merkle.erl}\n */\nconst common_1 = require(\"../common\");\nconst utils_1 = require(\"./utils\");\nexports.MAX_CHUNK_SIZE = 256 * 1024;\nexports.MIN_CHUNK_SIZE = 32 * 1024;\nconst NOTE_SIZE = 32;\nconst HASH_SIZE = 32;\n/**\n * Takes the input data and chunks it into (mostly) equal sized chunks.\n * The last chunk will be a bit smaller as it contains the remainder\n * from the chunking process.\n */\nasync function chunkData(data) {\n  let chunks = [];\n  let rest = data;\n  let cursor = 0;\n  while (rest.byteLength >= exports.MAX_CHUNK_SIZE) {\n    let chunkSize = exports.MAX_CHUNK_SIZE;\n    // If the total bytes left will produce a chunk < MIN_CHUNK_SIZE,\n    // then adjust the amount we put in this 2nd last chunk.\n    let nextChunkSize = rest.byteLength - exports.MAX_CHUNK_SIZE;\n    if (nextChunkSize > 0 && nextChunkSize < exports.MIN_CHUNK_SIZE) {\n      chunkSize = Math.ceil(rest.byteLength / 2);\n      // console.log(`Last chunk will be: ${nextChunkSize} which is below ${MIN_CHUNK_SIZE}, adjusting current to ${chunkSize} with ${rest.byteLength} left.`)\n    }\n    const chunk = rest.slice(0, chunkSize);\n    const dataHash = await common_1.default.crypto.hash(chunk);\n    cursor += chunk.byteLength;\n    chunks.push({\n      dataHash,\n      minByteRange: cursor - chunk.byteLength,\n      maxByteRange: cursor\n    });\n    rest = rest.slice(chunkSize);\n  }\n  chunks.push({\n    dataHash: await common_1.default.crypto.hash(rest),\n    minByteRange: cursor,\n    maxByteRange: cursor + rest.byteLength\n  });\n  return chunks;\n}\nasync function generateLeaves(chunks) {\n  return Promise.all(chunks.map(async ({\n    dataHash,\n    minByteRange,\n    maxByteRange\n  }) => {\n    return {\n      type: \"leaf\",\n      id: await hash(await Promise.all([hash(dataHash), hash(intToBuffer(maxByteRange))])),\n      dataHash: dataHash,\n      minByteRange,\n      maxByteRange\n    };\n  }));\n}\n/**\n * Builds an arweave merkle tree and gets the root hash for the given input.\n */\nasync function computeRootHash(data) {\n  const rootNode = await generateTree(data);\n  return rootNode.id;\n}\nasync function generateTree(data) {\n  const rootNode = await buildLayers(await generateLeaves(await chunkData(data)));\n  return rootNode;\n}\n/**\n * Generates the data_root, chunks & proofs\n * needed for a transaction.\n *\n * This also checks if the last chunk is a zero-length\n * chunk and discards that chunk and proof if so.\n * (we do not need to upload this zero length chunk)\n *\n * @param data\n */\nasync function generateTransactionChunks(data) {\n  const chunks = await chunkData(data);\n  const leaves = await generateLeaves(chunks);\n  const root = await buildLayers(leaves);\n  const proofs = await generateProofs(root);\n  // Discard the last chunk & proof if it's zero length.\n  const lastChunk = chunks.slice(-1)[0];\n  if (lastChunk.maxByteRange - lastChunk.minByteRange === 0) {\n    chunks.splice(chunks.length - 1, 1);\n    proofs.splice(proofs.length - 1, 1);\n  }\n  return {\n    data_root: root.id,\n    chunks,\n    proofs\n  };\n}\n/**\n * Starting with the bottom layer of leaf nodes, hash every second pair\n * into a new branch node, push those branch nodes onto a new layer,\n * and then recurse, building up the tree to it's root, where the\n * layer only consists of two items.\n */\nasync function buildLayers(nodes, level = 0) {\n  // If there is only 1 node left, this is going to be the root node\n  if (nodes.length < 2) {\n    const root = nodes[0];\n    // console.log(\"Root layer\", root);\n    return root;\n  }\n  const nextLayer = [];\n  for (let i = 0; i < nodes.length; i += 2) {\n    nextLayer.push(await hashBranch(nodes[i], nodes[i + 1]));\n  }\n  // console.log(\"Layer\", nextLayer);\n  return buildLayers(nextLayer, level + 1);\n}\n/**\n * Recursively search through all branches of the tree,\n * and generate a proof for each leaf node.\n */\nfunction generateProofs(root) {\n  const proofs = resolveBranchProofs(root);\n  if (!Array.isArray(proofs)) {\n    return [proofs];\n  }\n  return arrayFlatten(proofs);\n}\nfunction resolveBranchProofs(node, proof = new Uint8Array(), depth = 0) {\n  if (node.type == \"leaf\") {\n    return {\n      offset: node.maxByteRange - 1,\n      proof: (0, utils_1.concatBuffers)([proof, node.dataHash, intToBuffer(node.maxByteRange)])\n    };\n  }\n  if (node.type == \"branch\") {\n    const partialProof = (0, utils_1.concatBuffers)([proof, node.leftChild.id, node.rightChild.id, intToBuffer(node.byteRange)]);\n    return [resolveBranchProofs(node.leftChild, partialProof, depth + 1), resolveBranchProofs(node.rightChild, partialProof, depth + 1)];\n  }\n  throw new Error(`Unexpected node type`);\n}\nfunction arrayFlatten(input) {\n  const flat = [];\n  input.forEach(item => {\n    if (Array.isArray(item)) {\n      flat.push(...arrayFlatten(item));\n    } else {\n      flat.push(item);\n    }\n  });\n  return flat;\n}\nasync function hashBranch(left, right) {\n  if (!right) {\n    return left;\n  }\n  let branch = {\n    type: \"branch\",\n    id: await hash([await hash(left.id), await hash(right.id), await hash(intToBuffer(left.maxByteRange))]),\n    byteRange: left.maxByteRange,\n    maxByteRange: right.maxByteRange,\n    leftChild: left,\n    rightChild: right\n  };\n  return branch;\n}\nasync function hash(data) {\n  if (Array.isArray(data)) {\n    data = common_1.default.utils.concatBuffers(data);\n  }\n  return new Uint8Array(await common_1.default.crypto.hash(data));\n}\nfunction intToBuffer(note) {\n  const buffer = new Uint8Array(NOTE_SIZE);\n  for (var i = buffer.length - 1; i >= 0; i--) {\n    var byte = note % 256;\n    buffer[i] = byte;\n    note = (note - byte) / 256;\n  }\n  return buffer;\n}\nfunction bufferToInt(buffer) {\n  let value = 0;\n  for (var i = 0; i < buffer.length; i++) {\n    value *= 256;\n    value += buffer[i];\n  }\n  return value;\n}\nconst arrayCompare = (a, b) => a.every((value, index) => b[index] === value);\nexports.arrayCompare = arrayCompare;\nasync function validatePath(id, dest, leftBound, rightBound, path) {\n  if (rightBound <= 0) {\n    return false;\n  }\n  if (dest >= rightBound) {\n    return validatePath(id, 0, rightBound - 1, rightBound, path);\n  }\n  if (dest < 0) {\n    return validatePath(id, 0, 0, rightBound, path);\n  }\n  if (path.length == HASH_SIZE + NOTE_SIZE) {\n    const pathData = path.slice(0, HASH_SIZE);\n    const endOffsetBuffer = path.slice(pathData.length, pathData.length + NOTE_SIZE);\n    const pathDataHash = await hash([await hash(pathData), await hash(endOffsetBuffer)]);\n    let result = (0, exports.arrayCompare)(id, pathDataHash);\n    if (result) {\n      return {\n        offset: rightBound - 1,\n        leftBound: leftBound,\n        rightBound: rightBound,\n        chunkSize: rightBound - leftBound\n      };\n    }\n    return false;\n  }\n  const left = path.slice(0, HASH_SIZE);\n  const right = path.slice(left.length, left.length + HASH_SIZE);\n  const offsetBuffer = path.slice(left.length + right.length, left.length + right.length + NOTE_SIZE);\n  const offset = bufferToInt(offsetBuffer);\n  const remainder = path.slice(left.length + right.length + offsetBuffer.length);\n  const pathHash = await hash([await hash(left), await hash(right), await hash(offsetBuffer)]);\n  if ((0, exports.arrayCompare)(id, pathHash)) {\n    if (dest < offset) {\n      return await validatePath(left, dest, leftBound, Math.min(rightBound, offset), remainder);\n    }\n    return await validatePath(right, dest, Math.max(leftBound, offset), rightBound, remainder);\n  }\n  return false;\n}\n/**\n * Inspect an arweave chunk proof.\n * Takes proof, parses, reads and displays the values for console logging.\n * One proof section per line\n * Format: left,right,offset => hash\n */\nasync function debug(proof, output = \"\") {\n  if (proof.byteLength < 1) {\n    return output;\n  }\n  const left = proof.slice(0, HASH_SIZE);\n  const right = proof.slice(left.length, left.length + HASH_SIZE);\n  const offsetBuffer = proof.slice(left.length + right.length, left.length + right.length + NOTE_SIZE);\n  const offset = bufferToInt(offsetBuffer);\n  const remainder = proof.slice(left.length + right.length + offsetBuffer.length);\n  const pathHash = await hash([await hash(left), await hash(right), await hash(offsetBuffer)]);\n  const updatedOutput = `${output}\\n${JSON.stringify(Buffer.from(left))},${JSON.stringify(Buffer.from(right))},${offset} => ${JSON.stringify(pathHash)}`;\n  return debug(remainder, updatedOutput);\n}","map":{"version":3,"names":["Object","defineProperty","exports","value","arrayCompare","MIN_CHUNK_SIZE","MAX_CHUNK_SIZE","chunkData","generateLeaves","computeRootHash","generateTree","generateTransactionChunks","buildLayers","generateProofs","arrayFlatten","intToBuffer","bufferToInt","validatePath","debug","common_1","require","utils_1","NOTE_SIZE","HASH_SIZE","data","chunks","rest","cursor","byteLength","chunkSize","nextChunkSize","Math","ceil","chunk","slice","dataHash","default","crypto","hash","push","minByteRange","maxByteRange","Promise","all","map","type","id","rootNode","leaves","root","proofs","lastChunk","splice","length","data_root","nodes","level","nextLayer","i","hashBranch","resolveBranchProofs","Array","isArray","node","proof","Uint8Array","depth","offset","concatBuffers","partialProof","leftChild","rightChild","byteRange","Error","input","flat","forEach","item","left","right","branch","utils","note","buffer","byte","a","b","every","index","dest","leftBound","rightBound","path","pathData","endOffsetBuffer","pathDataHash","result","offsetBuffer","remainder","pathHash","min","max","output","updatedOutput","JSON","stringify","Buffer","from"],"sources":["C:/Users/adwai/perma-learn/frontend/node_modules/arweave/web/lib/merkle.js"],"sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.arrayCompare = exports.MIN_CHUNK_SIZE = exports.MAX_CHUNK_SIZE = void 0;\nexports.chunkData = chunkData;\nexports.generateLeaves = generateLeaves;\nexports.computeRootHash = computeRootHash;\nexports.generateTree = generateTree;\nexports.generateTransactionChunks = generateTransactionChunks;\nexports.buildLayers = buildLayers;\nexports.generateProofs = generateProofs;\nexports.arrayFlatten = arrayFlatten;\nexports.intToBuffer = intToBuffer;\nexports.bufferToInt = bufferToInt;\nexports.validatePath = validatePath;\nexports.debug = debug;\n/**\n * @see {@link https://github.com/ArweaveTeam/arweave/blob/fbc381e0e36efffa45d13f2faa6199d3766edaa2/apps/arweave/src/ar_merkle.erl}\n */\nconst common_1 = require(\"../common\");\nconst utils_1 = require(\"./utils\");\nexports.MAX_CHUNK_SIZE = 256 * 1024;\nexports.MIN_CHUNK_SIZE = 32 * 1024;\nconst NOTE_SIZE = 32;\nconst HASH_SIZE = 32;\n/**\n * Takes the input data and chunks it into (mostly) equal sized chunks.\n * The last chunk will be a bit smaller as it contains the remainder\n * from the chunking process.\n */\nasync function chunkData(data) {\n    let chunks = [];\n    let rest = data;\n    let cursor = 0;\n    while (rest.byteLength >= exports.MAX_CHUNK_SIZE) {\n        let chunkSize = exports.MAX_CHUNK_SIZE;\n        // If the total bytes left will produce a chunk < MIN_CHUNK_SIZE,\n        // then adjust the amount we put in this 2nd last chunk.\n        let nextChunkSize = rest.byteLength - exports.MAX_CHUNK_SIZE;\n        if (nextChunkSize > 0 && nextChunkSize < exports.MIN_CHUNK_SIZE) {\n            chunkSize = Math.ceil(rest.byteLength / 2);\n            // console.log(`Last chunk will be: ${nextChunkSize} which is below ${MIN_CHUNK_SIZE}, adjusting current to ${chunkSize} with ${rest.byteLength} left.`)\n        }\n        const chunk = rest.slice(0, chunkSize);\n        const dataHash = await common_1.default.crypto.hash(chunk);\n        cursor += chunk.byteLength;\n        chunks.push({\n            dataHash,\n            minByteRange: cursor - chunk.byteLength,\n            maxByteRange: cursor,\n        });\n        rest = rest.slice(chunkSize);\n    }\n    chunks.push({\n        dataHash: await common_1.default.crypto.hash(rest),\n        minByteRange: cursor,\n        maxByteRange: cursor + rest.byteLength,\n    });\n    return chunks;\n}\nasync function generateLeaves(chunks) {\n    return Promise.all(chunks.map(async ({ dataHash, minByteRange, maxByteRange }) => {\n        return {\n            type: \"leaf\",\n            id: await hash(await Promise.all([hash(dataHash), hash(intToBuffer(maxByteRange))])),\n            dataHash: dataHash,\n            minByteRange,\n            maxByteRange,\n        };\n    }));\n}\n/**\n * Builds an arweave merkle tree and gets the root hash for the given input.\n */\nasync function computeRootHash(data) {\n    const rootNode = await generateTree(data);\n    return rootNode.id;\n}\nasync function generateTree(data) {\n    const rootNode = await buildLayers(await generateLeaves(await chunkData(data)));\n    return rootNode;\n}\n/**\n * Generates the data_root, chunks & proofs\n * needed for a transaction.\n *\n * This also checks if the last chunk is a zero-length\n * chunk and discards that chunk and proof if so.\n * (we do not need to upload this zero length chunk)\n *\n * @param data\n */\nasync function generateTransactionChunks(data) {\n    const chunks = await chunkData(data);\n    const leaves = await generateLeaves(chunks);\n    const root = await buildLayers(leaves);\n    const proofs = await generateProofs(root);\n    // Discard the last chunk & proof if it's zero length.\n    const lastChunk = chunks.slice(-1)[0];\n    if (lastChunk.maxByteRange - lastChunk.minByteRange === 0) {\n        chunks.splice(chunks.length - 1, 1);\n        proofs.splice(proofs.length - 1, 1);\n    }\n    return {\n        data_root: root.id,\n        chunks,\n        proofs,\n    };\n}\n/**\n * Starting with the bottom layer of leaf nodes, hash every second pair\n * into a new branch node, push those branch nodes onto a new layer,\n * and then recurse, building up the tree to it's root, where the\n * layer only consists of two items.\n */\nasync function buildLayers(nodes, level = 0) {\n    // If there is only 1 node left, this is going to be the root node\n    if (nodes.length < 2) {\n        const root = nodes[0];\n        // console.log(\"Root layer\", root);\n        return root;\n    }\n    const nextLayer = [];\n    for (let i = 0; i < nodes.length; i += 2) {\n        nextLayer.push(await hashBranch(nodes[i], nodes[i + 1]));\n    }\n    // console.log(\"Layer\", nextLayer);\n    return buildLayers(nextLayer, level + 1);\n}\n/**\n * Recursively search through all branches of the tree,\n * and generate a proof for each leaf node.\n */\nfunction generateProofs(root) {\n    const proofs = resolveBranchProofs(root);\n    if (!Array.isArray(proofs)) {\n        return [proofs];\n    }\n    return arrayFlatten(proofs);\n}\nfunction resolveBranchProofs(node, proof = new Uint8Array(), depth = 0) {\n    if (node.type == \"leaf\") {\n        return {\n            offset: node.maxByteRange - 1,\n            proof: (0, utils_1.concatBuffers)([\n                proof,\n                node.dataHash,\n                intToBuffer(node.maxByteRange),\n            ]),\n        };\n    }\n    if (node.type == \"branch\") {\n        const partialProof = (0, utils_1.concatBuffers)([\n            proof,\n            node.leftChild.id,\n            node.rightChild.id,\n            intToBuffer(node.byteRange),\n        ]);\n        return [\n            resolveBranchProofs(node.leftChild, partialProof, depth + 1),\n            resolveBranchProofs(node.rightChild, partialProof, depth + 1),\n        ];\n    }\n    throw new Error(`Unexpected node type`);\n}\nfunction arrayFlatten(input) {\n    const flat = [];\n    input.forEach((item) => {\n        if (Array.isArray(item)) {\n            flat.push(...arrayFlatten(item));\n        }\n        else {\n            flat.push(item);\n        }\n    });\n    return flat;\n}\nasync function hashBranch(left, right) {\n    if (!right) {\n        return left;\n    }\n    let branch = {\n        type: \"branch\",\n        id: await hash([\n            await hash(left.id),\n            await hash(right.id),\n            await hash(intToBuffer(left.maxByteRange)),\n        ]),\n        byteRange: left.maxByteRange,\n        maxByteRange: right.maxByteRange,\n        leftChild: left,\n        rightChild: right,\n    };\n    return branch;\n}\nasync function hash(data) {\n    if (Array.isArray(data)) {\n        data = common_1.default.utils.concatBuffers(data);\n    }\n    return new Uint8Array(await common_1.default.crypto.hash(data));\n}\nfunction intToBuffer(note) {\n    const buffer = new Uint8Array(NOTE_SIZE);\n    for (var i = buffer.length - 1; i >= 0; i--) {\n        var byte = note % 256;\n        buffer[i] = byte;\n        note = (note - byte) / 256;\n    }\n    return buffer;\n}\nfunction bufferToInt(buffer) {\n    let value = 0;\n    for (var i = 0; i < buffer.length; i++) {\n        value *= 256;\n        value += buffer[i];\n    }\n    return value;\n}\nconst arrayCompare = (a, b) => a.every((value, index) => b[index] === value);\nexports.arrayCompare = arrayCompare;\nasync function validatePath(id, dest, leftBound, rightBound, path) {\n    if (rightBound <= 0) {\n        return false;\n    }\n    if (dest >= rightBound) {\n        return validatePath(id, 0, rightBound - 1, rightBound, path);\n    }\n    if (dest < 0) {\n        return validatePath(id, 0, 0, rightBound, path);\n    }\n    if (path.length == HASH_SIZE + NOTE_SIZE) {\n        const pathData = path.slice(0, HASH_SIZE);\n        const endOffsetBuffer = path.slice(pathData.length, pathData.length + NOTE_SIZE);\n        const pathDataHash = await hash([\n            await hash(pathData),\n            await hash(endOffsetBuffer),\n        ]);\n        let result = (0, exports.arrayCompare)(id, pathDataHash);\n        if (result) {\n            return {\n                offset: rightBound - 1,\n                leftBound: leftBound,\n                rightBound: rightBound,\n                chunkSize: rightBound - leftBound,\n            };\n        }\n        return false;\n    }\n    const left = path.slice(0, HASH_SIZE);\n    const right = path.slice(left.length, left.length + HASH_SIZE);\n    const offsetBuffer = path.slice(left.length + right.length, left.length + right.length + NOTE_SIZE);\n    const offset = bufferToInt(offsetBuffer);\n    const remainder = path.slice(left.length + right.length + offsetBuffer.length);\n    const pathHash = await hash([\n        await hash(left),\n        await hash(right),\n        await hash(offsetBuffer),\n    ]);\n    if ((0, exports.arrayCompare)(id, pathHash)) {\n        if (dest < offset) {\n            return await validatePath(left, dest, leftBound, Math.min(rightBound, offset), remainder);\n        }\n        return await validatePath(right, dest, Math.max(leftBound, offset), rightBound, remainder);\n    }\n    return false;\n}\n/**\n * Inspect an arweave chunk proof.\n * Takes proof, parses, reads and displays the values for console logging.\n * One proof section per line\n * Format: left,right,offset => hash\n */\nasync function debug(proof, output = \"\") {\n    if (proof.byteLength < 1) {\n        return output;\n    }\n    const left = proof.slice(0, HASH_SIZE);\n    const right = proof.slice(left.length, left.length + HASH_SIZE);\n    const offsetBuffer = proof.slice(left.length + right.length, left.length + right.length + NOTE_SIZE);\n    const offset = bufferToInt(offsetBuffer);\n    const remainder = proof.slice(left.length + right.length + offsetBuffer.length);\n    const pathHash = await hash([\n        await hash(left),\n        await hash(right),\n        await hash(offsetBuffer),\n    ]);\n    const updatedOutput = `${output}\\n${JSON.stringify(Buffer.from(left))},${JSON.stringify(Buffer.from(right))},${offset} => ${JSON.stringify(pathHash)}`;\n    return debug(remainder, updatedOutput);\n}\n"],"mappings":"AAAA,YAAY;;AACZA,MAAM,CAACC,cAAc,CAACC,OAAO,EAAE,YAAY,EAAE;EAAEC,KAAK,EAAE;AAAK,CAAC,CAAC;AAC7DD,OAAO,CAACE,YAAY,GAAGF,OAAO,CAACG,cAAc,GAAGH,OAAO,CAACI,cAAc,GAAG,KAAK,CAAC;AAC/EJ,OAAO,CAACK,SAAS,GAAGA,SAAS;AAC7BL,OAAO,CAACM,cAAc,GAAGA,cAAc;AACvCN,OAAO,CAACO,eAAe,GAAGA,eAAe;AACzCP,OAAO,CAACQ,YAAY,GAAGA,YAAY;AACnCR,OAAO,CAACS,yBAAyB,GAAGA,yBAAyB;AAC7DT,OAAO,CAACU,WAAW,GAAGA,WAAW;AACjCV,OAAO,CAACW,cAAc,GAAGA,cAAc;AACvCX,OAAO,CAACY,YAAY,GAAGA,YAAY;AACnCZ,OAAO,CAACa,WAAW,GAAGA,WAAW;AACjCb,OAAO,CAACc,WAAW,GAAGA,WAAW;AACjCd,OAAO,CAACe,YAAY,GAAGA,YAAY;AACnCf,OAAO,CAACgB,KAAK,GAAGA,KAAK;AACrB;AACA;AACA;AACA,MAAMC,QAAQ,GAAGC,OAAO,CAAC,WAAW,CAAC;AACrC,MAAMC,OAAO,GAAGD,OAAO,CAAC,SAAS,CAAC;AAClClB,OAAO,CAACI,cAAc,GAAG,GAAG,GAAG,IAAI;AACnCJ,OAAO,CAACG,cAAc,GAAG,EAAE,GAAG,IAAI;AAClC,MAAMiB,SAAS,GAAG,EAAE;AACpB,MAAMC,SAAS,GAAG,EAAE;AACpB;AACA;AACA;AACA;AACA;AACA,eAAehB,SAASA,CAACiB,IAAI,EAAE;EAC3B,IAAIC,MAAM,GAAG,EAAE;EACf,IAAIC,IAAI,GAAGF,IAAI;EACf,IAAIG,MAAM,GAAG,CAAC;EACd,OAAOD,IAAI,CAACE,UAAU,IAAI1B,OAAO,CAACI,cAAc,EAAE;IAC9C,IAAIuB,SAAS,GAAG3B,OAAO,CAACI,cAAc;IACtC;IACA;IACA,IAAIwB,aAAa,GAAGJ,IAAI,CAACE,UAAU,GAAG1B,OAAO,CAACI,cAAc;IAC5D,IAAIwB,aAAa,GAAG,CAAC,IAAIA,aAAa,GAAG5B,OAAO,CAACG,cAAc,EAAE;MAC7DwB,SAAS,GAAGE,IAAI,CAACC,IAAI,CAACN,IAAI,CAACE,UAAU,GAAG,CAAC,CAAC;MAC1C;IACJ;IACA,MAAMK,KAAK,GAAGP,IAAI,CAACQ,KAAK,CAAC,CAAC,EAAEL,SAAS,CAAC;IACtC,MAAMM,QAAQ,GAAG,MAAMhB,QAAQ,CAACiB,OAAO,CAACC,MAAM,CAACC,IAAI,CAACL,KAAK,CAAC;IAC1DN,MAAM,IAAIM,KAAK,CAACL,UAAU;IAC1BH,MAAM,CAACc,IAAI,CAAC;MACRJ,QAAQ;MACRK,YAAY,EAAEb,MAAM,GAAGM,KAAK,CAACL,UAAU;MACvCa,YAAY,EAAEd;IAClB,CAAC,CAAC;IACFD,IAAI,GAAGA,IAAI,CAACQ,KAAK,CAACL,SAAS,CAAC;EAChC;EACAJ,MAAM,CAACc,IAAI,CAAC;IACRJ,QAAQ,EAAE,MAAMhB,QAAQ,CAACiB,OAAO,CAACC,MAAM,CAACC,IAAI,CAACZ,IAAI,CAAC;IAClDc,YAAY,EAAEb,MAAM;IACpBc,YAAY,EAAEd,MAAM,GAAGD,IAAI,CAACE;EAChC,CAAC,CAAC;EACF,OAAOH,MAAM;AACjB;AACA,eAAejB,cAAcA,CAACiB,MAAM,EAAE;EAClC,OAAOiB,OAAO,CAACC,GAAG,CAAClB,MAAM,CAACmB,GAAG,CAAC,OAAO;IAAET,QAAQ;IAAEK,YAAY;IAAEC;EAAa,CAAC,KAAK;IAC9E,OAAO;MACHI,IAAI,EAAE,MAAM;MACZC,EAAE,EAAE,MAAMR,IAAI,CAAC,MAAMI,OAAO,CAACC,GAAG,CAAC,CAACL,IAAI,CAACH,QAAQ,CAAC,EAAEG,IAAI,CAACvB,WAAW,CAAC0B,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC;MACpFN,QAAQ,EAAEA,QAAQ;MAClBK,YAAY;MACZC;IACJ,CAAC;EACL,CAAC,CAAC,CAAC;AACP;AACA;AACA;AACA;AACA,eAAehC,eAAeA,CAACe,IAAI,EAAE;EACjC,MAAMuB,QAAQ,GAAG,MAAMrC,YAAY,CAACc,IAAI,CAAC;EACzC,OAAOuB,QAAQ,CAACD,EAAE;AACtB;AACA,eAAepC,YAAYA,CAACc,IAAI,EAAE;EAC9B,MAAMuB,QAAQ,GAAG,MAAMnC,WAAW,CAAC,MAAMJ,cAAc,CAAC,MAAMD,SAAS,CAACiB,IAAI,CAAC,CAAC,CAAC;EAC/E,OAAOuB,QAAQ;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAepC,yBAAyBA,CAACa,IAAI,EAAE;EAC3C,MAAMC,MAAM,GAAG,MAAMlB,SAAS,CAACiB,IAAI,CAAC;EACpC,MAAMwB,MAAM,GAAG,MAAMxC,cAAc,CAACiB,MAAM,CAAC;EAC3C,MAAMwB,IAAI,GAAG,MAAMrC,WAAW,CAACoC,MAAM,CAAC;EACtC,MAAME,MAAM,GAAG,MAAMrC,cAAc,CAACoC,IAAI,CAAC;EACzC;EACA,MAAME,SAAS,GAAG1B,MAAM,CAACS,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;EACrC,IAAIiB,SAAS,CAACV,YAAY,GAAGU,SAAS,CAACX,YAAY,KAAK,CAAC,EAAE;IACvDf,MAAM,CAAC2B,MAAM,CAAC3B,MAAM,CAAC4B,MAAM,GAAG,CAAC,EAAE,CAAC,CAAC;IACnCH,MAAM,CAACE,MAAM,CAACF,MAAM,CAACG,MAAM,GAAG,CAAC,EAAE,CAAC,CAAC;EACvC;EACA,OAAO;IACHC,SAAS,EAAEL,IAAI,CAACH,EAAE;IAClBrB,MAAM;IACNyB;EACJ,CAAC;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAetC,WAAWA,CAAC2C,KAAK,EAAEC,KAAK,GAAG,CAAC,EAAE;EACzC;EACA,IAAID,KAAK,CAACF,MAAM,GAAG,CAAC,EAAE;IAClB,MAAMJ,IAAI,GAAGM,KAAK,CAAC,CAAC,CAAC;IACrB;IACA,OAAON,IAAI;EACf;EACA,MAAMQ,SAAS,GAAG,EAAE;EACpB,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGH,KAAK,CAACF,MAAM,EAAEK,CAAC,IAAI,CAAC,EAAE;IACtCD,SAAS,CAAClB,IAAI,CAAC,MAAMoB,UAAU,CAACJ,KAAK,CAACG,CAAC,CAAC,EAAEH,KAAK,CAACG,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;EAC5D;EACA;EACA,OAAO9C,WAAW,CAAC6C,SAAS,EAAED,KAAK,GAAG,CAAC,CAAC;AAC5C;AACA;AACA;AACA;AACA;AACA,SAAS3C,cAAcA,CAACoC,IAAI,EAAE;EAC1B,MAAMC,MAAM,GAAGU,mBAAmB,CAACX,IAAI,CAAC;EACxC,IAAI,CAACY,KAAK,CAACC,OAAO,CAACZ,MAAM,CAAC,EAAE;IACxB,OAAO,CAACA,MAAM,CAAC;EACnB;EACA,OAAOpC,YAAY,CAACoC,MAAM,CAAC;AAC/B;AACA,SAASU,mBAAmBA,CAACG,IAAI,EAAEC,KAAK,GAAG,IAAIC,UAAU,CAAC,CAAC,EAAEC,KAAK,GAAG,CAAC,EAAE;EACpE,IAAIH,IAAI,CAAClB,IAAI,IAAI,MAAM,EAAE;IACrB,OAAO;MACHsB,MAAM,EAAEJ,IAAI,CAACtB,YAAY,GAAG,CAAC;MAC7BuB,KAAK,EAAE,CAAC,CAAC,EAAE3C,OAAO,CAAC+C,aAAa,EAAE,CAC9BJ,KAAK,EACLD,IAAI,CAAC5B,QAAQ,EACbpB,WAAW,CAACgD,IAAI,CAACtB,YAAY,CAAC,CACjC;IACL,CAAC;EACL;EACA,IAAIsB,IAAI,CAAClB,IAAI,IAAI,QAAQ,EAAE;IACvB,MAAMwB,YAAY,GAAG,CAAC,CAAC,EAAEhD,OAAO,CAAC+C,aAAa,EAAE,CAC5CJ,KAAK,EACLD,IAAI,CAACO,SAAS,CAACxB,EAAE,EACjBiB,IAAI,CAACQ,UAAU,CAACzB,EAAE,EAClB/B,WAAW,CAACgD,IAAI,CAACS,SAAS,CAAC,CAC9B,CAAC;IACF,OAAO,CACHZ,mBAAmB,CAACG,IAAI,CAACO,SAAS,EAAED,YAAY,EAAEH,KAAK,GAAG,CAAC,CAAC,EAC5DN,mBAAmB,CAACG,IAAI,CAACQ,UAAU,EAAEF,YAAY,EAAEH,KAAK,GAAG,CAAC,CAAC,CAChE;EACL;EACA,MAAM,IAAIO,KAAK,CAAC,sBAAsB,CAAC;AAC3C;AACA,SAAS3D,YAAYA,CAAC4D,KAAK,EAAE;EACzB,MAAMC,IAAI,GAAG,EAAE;EACfD,KAAK,CAACE,OAAO,CAAEC,IAAI,IAAK;IACpB,IAAIhB,KAAK,CAACC,OAAO,CAACe,IAAI,CAAC,EAAE;MACrBF,IAAI,CAACpC,IAAI,CAAC,GAAGzB,YAAY,CAAC+D,IAAI,CAAC,CAAC;IACpC,CAAC,MACI;MACDF,IAAI,CAACpC,IAAI,CAACsC,IAAI,CAAC;IACnB;EACJ,CAAC,CAAC;EACF,OAAOF,IAAI;AACf;AACA,eAAehB,UAAUA,CAACmB,IAAI,EAAEC,KAAK,EAAE;EACnC,IAAI,CAACA,KAAK,EAAE;IACR,OAAOD,IAAI;EACf;EACA,IAAIE,MAAM,GAAG;IACTnC,IAAI,EAAE,QAAQ;IACdC,EAAE,EAAE,MAAMR,IAAI,CAAC,CACX,MAAMA,IAAI,CAACwC,IAAI,CAAChC,EAAE,CAAC,EACnB,MAAMR,IAAI,CAACyC,KAAK,CAACjC,EAAE,CAAC,EACpB,MAAMR,IAAI,CAACvB,WAAW,CAAC+D,IAAI,CAACrC,YAAY,CAAC,CAAC,CAC7C,CAAC;IACF+B,SAAS,EAAEM,IAAI,CAACrC,YAAY;IAC5BA,YAAY,EAAEsC,KAAK,CAACtC,YAAY;IAChC6B,SAAS,EAAEQ,IAAI;IACfP,UAAU,EAAEQ;EAChB,CAAC;EACD,OAAOC,MAAM;AACjB;AACA,eAAe1C,IAAIA,CAACd,IAAI,EAAE;EACtB,IAAIqC,KAAK,CAACC,OAAO,CAACtC,IAAI,CAAC,EAAE;IACrBA,IAAI,GAAGL,QAAQ,CAACiB,OAAO,CAAC6C,KAAK,CAACb,aAAa,CAAC5C,IAAI,CAAC;EACrD;EACA,OAAO,IAAIyC,UAAU,CAAC,MAAM9C,QAAQ,CAACiB,OAAO,CAACC,MAAM,CAACC,IAAI,CAACd,IAAI,CAAC,CAAC;AACnE;AACA,SAAST,WAAWA,CAACmE,IAAI,EAAE;EACvB,MAAMC,MAAM,GAAG,IAAIlB,UAAU,CAAC3C,SAAS,CAAC;EACxC,KAAK,IAAIoC,CAAC,GAAGyB,MAAM,CAAC9B,MAAM,GAAG,CAAC,EAAEK,CAAC,IAAI,CAAC,EAAEA,CAAC,EAAE,EAAE;IACzC,IAAI0B,IAAI,GAAGF,IAAI,GAAG,GAAG;IACrBC,MAAM,CAACzB,CAAC,CAAC,GAAG0B,IAAI;IAChBF,IAAI,GAAG,CAACA,IAAI,GAAGE,IAAI,IAAI,GAAG;EAC9B;EACA,OAAOD,MAAM;AACjB;AACA,SAASnE,WAAWA,CAACmE,MAAM,EAAE;EACzB,IAAIhF,KAAK,GAAG,CAAC;EACb,KAAK,IAAIuD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGyB,MAAM,CAAC9B,MAAM,EAAEK,CAAC,EAAE,EAAE;IACpCvD,KAAK,IAAI,GAAG;IACZA,KAAK,IAAIgF,MAAM,CAACzB,CAAC,CAAC;EACtB;EACA,OAAOvD,KAAK;AAChB;AACA,MAAMC,YAAY,GAAGA,CAACiF,CAAC,EAAEC,CAAC,KAAKD,CAAC,CAACE,KAAK,CAAC,CAACpF,KAAK,EAAEqF,KAAK,KAAKF,CAAC,CAACE,KAAK,CAAC,KAAKrF,KAAK,CAAC;AAC5ED,OAAO,CAACE,YAAY,GAAGA,YAAY;AACnC,eAAea,YAAYA,CAAC6B,EAAE,EAAE2C,IAAI,EAAEC,SAAS,EAAEC,UAAU,EAAEC,IAAI,EAAE;EAC/D,IAAID,UAAU,IAAI,CAAC,EAAE;IACjB,OAAO,KAAK;EAChB;EACA,IAAIF,IAAI,IAAIE,UAAU,EAAE;IACpB,OAAO1E,YAAY,CAAC6B,EAAE,EAAE,CAAC,EAAE6C,UAAU,GAAG,CAAC,EAAEA,UAAU,EAAEC,IAAI,CAAC;EAChE;EACA,IAAIH,IAAI,GAAG,CAAC,EAAE;IACV,OAAOxE,YAAY,CAAC6B,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE6C,UAAU,EAAEC,IAAI,CAAC;EACnD;EACA,IAAIA,IAAI,CAACvC,MAAM,IAAI9B,SAAS,GAAGD,SAAS,EAAE;IACtC,MAAMuE,QAAQ,GAAGD,IAAI,CAAC1D,KAAK,CAAC,CAAC,EAAEX,SAAS,CAAC;IACzC,MAAMuE,eAAe,GAAGF,IAAI,CAAC1D,KAAK,CAAC2D,QAAQ,CAACxC,MAAM,EAAEwC,QAAQ,CAACxC,MAAM,GAAG/B,SAAS,CAAC;IAChF,MAAMyE,YAAY,GAAG,MAAMzD,IAAI,CAAC,CAC5B,MAAMA,IAAI,CAACuD,QAAQ,CAAC,EACpB,MAAMvD,IAAI,CAACwD,eAAe,CAAC,CAC9B,CAAC;IACF,IAAIE,MAAM,GAAG,CAAC,CAAC,EAAE9F,OAAO,CAACE,YAAY,EAAE0C,EAAE,EAAEiD,YAAY,CAAC;IACxD,IAAIC,MAAM,EAAE;MACR,OAAO;QACH7B,MAAM,EAAEwB,UAAU,GAAG,CAAC;QACtBD,SAAS,EAAEA,SAAS;QACpBC,UAAU,EAAEA,UAAU;QACtB9D,SAAS,EAAE8D,UAAU,GAAGD;MAC5B,CAAC;IACL;IACA,OAAO,KAAK;EAChB;EACA,MAAMZ,IAAI,GAAGc,IAAI,CAAC1D,KAAK,CAAC,CAAC,EAAEX,SAAS,CAAC;EACrC,MAAMwD,KAAK,GAAGa,IAAI,CAAC1D,KAAK,CAAC4C,IAAI,CAACzB,MAAM,EAAEyB,IAAI,CAACzB,MAAM,GAAG9B,SAAS,CAAC;EAC9D,MAAM0E,YAAY,GAAGL,IAAI,CAAC1D,KAAK,CAAC4C,IAAI,CAACzB,MAAM,GAAG0B,KAAK,CAAC1B,MAAM,EAAEyB,IAAI,CAACzB,MAAM,GAAG0B,KAAK,CAAC1B,MAAM,GAAG/B,SAAS,CAAC;EACnG,MAAM6C,MAAM,GAAGnD,WAAW,CAACiF,YAAY,CAAC;EACxC,MAAMC,SAAS,GAAGN,IAAI,CAAC1D,KAAK,CAAC4C,IAAI,CAACzB,MAAM,GAAG0B,KAAK,CAAC1B,MAAM,GAAG4C,YAAY,CAAC5C,MAAM,CAAC;EAC9E,MAAM8C,QAAQ,GAAG,MAAM7D,IAAI,CAAC,CACxB,MAAMA,IAAI,CAACwC,IAAI,CAAC,EAChB,MAAMxC,IAAI,CAACyC,KAAK,CAAC,EACjB,MAAMzC,IAAI,CAAC2D,YAAY,CAAC,CAC3B,CAAC;EACF,IAAI,CAAC,CAAC,EAAE/F,OAAO,CAACE,YAAY,EAAE0C,EAAE,EAAEqD,QAAQ,CAAC,EAAE;IACzC,IAAIV,IAAI,GAAGtB,MAAM,EAAE;MACf,OAAO,MAAMlD,YAAY,CAAC6D,IAAI,EAAEW,IAAI,EAAEC,SAAS,EAAE3D,IAAI,CAACqE,GAAG,CAACT,UAAU,EAAExB,MAAM,CAAC,EAAE+B,SAAS,CAAC;IAC7F;IACA,OAAO,MAAMjF,YAAY,CAAC8D,KAAK,EAAEU,IAAI,EAAE1D,IAAI,CAACsE,GAAG,CAACX,SAAS,EAAEvB,MAAM,CAAC,EAAEwB,UAAU,EAAEO,SAAS,CAAC;EAC9F;EACA,OAAO,KAAK;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAehF,KAAKA,CAAC8C,KAAK,EAAEsC,MAAM,GAAG,EAAE,EAAE;EACrC,IAAItC,KAAK,CAACpC,UAAU,GAAG,CAAC,EAAE;IACtB,OAAO0E,MAAM;EACjB;EACA,MAAMxB,IAAI,GAAGd,KAAK,CAAC9B,KAAK,CAAC,CAAC,EAAEX,SAAS,CAAC;EACtC,MAAMwD,KAAK,GAAGf,KAAK,CAAC9B,KAAK,CAAC4C,IAAI,CAACzB,MAAM,EAAEyB,IAAI,CAACzB,MAAM,GAAG9B,SAAS,CAAC;EAC/D,MAAM0E,YAAY,GAAGjC,KAAK,CAAC9B,KAAK,CAAC4C,IAAI,CAACzB,MAAM,GAAG0B,KAAK,CAAC1B,MAAM,EAAEyB,IAAI,CAACzB,MAAM,GAAG0B,KAAK,CAAC1B,MAAM,GAAG/B,SAAS,CAAC;EACpG,MAAM6C,MAAM,GAAGnD,WAAW,CAACiF,YAAY,CAAC;EACxC,MAAMC,SAAS,GAAGlC,KAAK,CAAC9B,KAAK,CAAC4C,IAAI,CAACzB,MAAM,GAAG0B,KAAK,CAAC1B,MAAM,GAAG4C,YAAY,CAAC5C,MAAM,CAAC;EAC/E,MAAM8C,QAAQ,GAAG,MAAM7D,IAAI,CAAC,CACxB,MAAMA,IAAI,CAACwC,IAAI,CAAC,EAChB,MAAMxC,IAAI,CAACyC,KAAK,CAAC,EACjB,MAAMzC,IAAI,CAAC2D,YAAY,CAAC,CAC3B,CAAC;EACF,MAAMM,aAAa,GAAG,GAAGD,MAAM,KAAKE,IAAI,CAACC,SAAS,CAACC,MAAM,CAACC,IAAI,CAAC7B,IAAI,CAAC,CAAC,IAAI0B,IAAI,CAACC,SAAS,CAACC,MAAM,CAACC,IAAI,CAAC5B,KAAK,CAAC,CAAC,IAAIZ,MAAM,OAAOqC,IAAI,CAACC,SAAS,CAACN,QAAQ,CAAC,EAAE;EACtJ,OAAOjF,KAAK,CAACgF,SAAS,EAAEK,aAAa,CAAC;AAC1C","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}